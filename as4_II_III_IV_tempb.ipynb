{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlVgMFow8Ib0",
        "outputId": "8e935baf-6378-4b84-b4e7-7feefc132163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "from importlib import import_module\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.api._v2 import keras as KerasAPI\n",
        "keras: KerasAPI = import_module(\"tensorflow.keras\")\n",
        "print(tf.__version__)\n",
        "\n",
        "from keras import Model, layers\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from keras.utils import load_img\n",
        "from keras.utils import img_to_array\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IswFMVHz8Ib1",
        "outputId": "c3ef8a27-3bbe-4de2-edaa-ba72eae0109c"
      },
      "outputs": [],
      "source": [
        "path = ''\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# path = '/content/drive/MyDrive/deepLearningAs3/'\n",
        "\n",
        "pathfinal = path + 'model_history_II_tempb/'\n",
        "pathfinal2 = path + 'model_images/'\n",
        "\n",
        "epoch_val = 3000\n",
        "batch_size_val = 32\n",
        "threshold_val = 1e-4\n",
        "inputShape = 784\n",
        "\n",
        "random_state_global = 42\n",
        "learning_rate_val = 1e-3\n",
        "\n",
        "Hidden_layer_I_N = 25\n",
        "Hidden_layer_II_N = 20\n",
        "Hidden_layer_III_N = 15\n",
        "Output_layer_N = 5\n",
        "\n",
        "Hidden_layer_ED_N = 400\n",
        "\n",
        "Hidden_layer_Activation = \"tanh\"\n",
        "Output_layer_Activation = \"softmax\"\n",
        "\n",
        "Output_layer_Encoder_Activation = \"linear\"\n",
        "\n",
        "\n",
        "epsilon_val = 1e-8\n",
        "beta_1_val = 0.9\n",
        "beta_2_val = 0.999\n",
        "\n",
        "\n",
        "class_l_r_to_d = {0:0, 1:1, 2:2, 4:3, 9:4}\n",
        "class_l_d_to_r = {0:0, 1:1, 2:2, 3:4, 4:9}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def delete_folder_contents(pathfinal):\n",
        "    folder_name = pathfinal\n",
        "    # Get all files in the folder\n",
        "    files = os.listdir(folder_name)\n",
        "\n",
        "    # Loop through the files and delete them\n",
        "    for file in files:\n",
        "        file_path = os.path.join(folder_name, file)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "            if os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "delete_folder_contents(pathfinal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixIH2x9y8Ib1"
      },
      "source": [
        "read and saving data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnvJ1CcX8Ib2",
        "outputId": "c57204f1-b891-4888-ffd3-8266967d60ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skipping\n"
          ]
        }
      ],
      "source": [
        "%%script echo skipping\n",
        "# level 0 path\n",
        "l0 = 'Group_20'\n",
        "\n",
        "DATASET = {0:pd.DataFrame(), 1:pd.DataFrame(), 2:pd.DataFrame()}\n",
        "temp_dict = {'train':0, 'val':1, 'test':2}\n",
        "\n",
        "# iterate over files in\n",
        "# that l0\n",
        "for l1 in os.listdir(l0):\n",
        "    f1 = os.path.join(l0, l1)\n",
        "    for l2 in os.listdir(f1):\n",
        "        f2 = os.path.join(f1, l2)\n",
        "        for l3 in os.listdir(f2):\n",
        "            f3 = os.path.join(f2, l3)\n",
        "            # print(f3)\n",
        "            img = load_img(f3, color_mode = \"grayscale\")\n",
        "            data_point = tf.squeeze(tf.constant(img_to_array(img)))\n",
        "            # print(\"shape:\", data_point.shape) # shape: (28, 28)\n",
        "            # data_point = data_point/255\n",
        "            # print(tf.math.reduce_min(data_point), tf.math.reduce_max(data_point))\n",
        "            # plt.imshow(data_point)\n",
        "            # plt.show()\n",
        "\n",
        "            temp = tf.reshape(data_point, shape=[-1]).numpy().tolist()\n",
        "            \n",
        "            #appending label\n",
        "            temp.append(int(l2))\n",
        "\n",
        "            # print(\"shape:\",temp.shape) #shape: (784,)\n",
        "            row = pd.Series(temp)\n",
        "            # print('1')\n",
        "            DATASET[temp_dict[l1]] = pd.concat([DATASET[temp_dict[l1]], row], axis=1)\n",
        "            # plt.imshow(tf.reshape(temp, shape=(28,28)))\n",
        "            # plt.show()\n",
        "\n",
        "\n",
        "df_train = DATASET[0].transpose()\n",
        "df_valid = DATASET[1].transpose()\n",
        "df_test = DATASET[2].transpose()\n",
        "\n",
        "## saving data\n",
        "df_train.to_csv('df_train.csv', index=False)\n",
        "df_valid.to_csv('df_valid.csv', index=False)\n",
        "df_test.to_csv('df_test.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "o4AdQBBU8Ib3"
      },
      "outputs": [],
      "source": [
        "def label_encoding(df):\n",
        "    df[df.columns[-1]] = LabelEncoder().fit_transform(df.iloc[:,-1])\n",
        "    return df\n",
        "\n",
        "def normalizing_data(df):\n",
        "    temp = df[df.columns[-1]]\n",
        "    df = df/255\n",
        "    df[df.columns[-1]] = temp\n",
        "    return df\n",
        "\n",
        "def data_visualize(df):\n",
        "  np.random.seed(random_state_global)\n",
        "  fig, axis = plt.subplots(3, 3, figsize=(6, 6))\n",
        "  axis = axis.reshape(-1)\n",
        "  for i in range(9):\n",
        "    rand_index = np.random.choice(range(len(df)))\n",
        "    axis[i].imshow(tf.reshape(df.iloc[rand_index,:-1], shape=(28,28)))\n",
        "    axis[i].set_title(f'{class_l_d_to_r[df.iloc[rand_index,-1]]}')\n",
        "    axis[i].axis(False)\n",
        "  fig.suptitle(\"Data\")\n",
        "  plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3qcBCIO8Ib3",
        "outputId": "e7b07879-395d-4a1b-8de1-0eefe5b01b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_train: {0.0: 2277, 1.0: 2277, 2.0: 2277, 4.0: 2277, 9.0: 2277}\n",
            "df_valid: {0.0: 759, 1.0: 759, 2.0: 759, 4.0: 759, 9.0: 759}\n",
            "df_test: {0.0: 759, 1.0: 759, 2.0: 759, 4.0: 759, 9.0: 759}\n",
            "\n",
            "Initial Data Range: 0.0 to 255.0\n",
            "Final Data Range: 0.0 to 1.0\n",
            "Label Encoded\n",
            "Train Data (11385, 785)\n",
            "Valid Data (3795, 785)\n",
            "Test Data (3795, 785)\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.read_csv(path+'df_train.csv', dtype='float32')\n",
        "df_valid = pd.read_csv(path+'df_valid.csv', dtype='float32')\n",
        "df_test = pd.read_csv(path+'df_test.csv', dtype='float32')\n",
        "\n",
        "print('df_train:', df_train.groupby(['784']).count().iloc[:,-1].to_dict())\n",
        "print('df_valid:', df_valid.groupby(['784']).count().iloc[:,-1].to_dict())\n",
        "print('df_test:', df_test.groupby(['784']).count().iloc[:,-1].to_dict())\n",
        "print()\n",
        "\n",
        "print(f'Initial Data Range: {min(df_train.iloc[:,:-1].min())} to {max(df_train.iloc[:,:-1].max())}')\n",
        "\n",
        "df_train = label_encoding(normalizing_data(df_train))\n",
        "df_valid = label_encoding(normalizing_data(df_valid))\n",
        "df_test = label_encoding(normalizing_data(df_test))\n",
        "print(f'Final Data Range: {min(df_train.iloc[:,:-1].min())} to {max(df_train.iloc[:,:-1].max())}')\n",
        "print('Label Encoded')\n",
        "\n",
        "print('Train Data',df_train.shape)\n",
        "print('Valid Data',df_valid.shape)\n",
        "print('Test Data' ,df_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "I24PGZRL8Ib3",
        "outputId": "6ef2def1-f5aa-4547-cc55-87372a0a5889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1\n",
            "\n",
            "systemMemory: 8.00 GB\n",
            "maxCacheSize: 2.67 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-16 23:00:22.006330: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-04-16 23:00:22.006425: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_visualize(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CtPn8eQq8Ib4"
      },
      "outputs": [],
      "source": [
        "# class StopOnThreshold(keras.callbacks.Callback):\n",
        "#     def __init__(self, threshold):\n",
        "#         super(StopOnThreshold, self).__init__()\n",
        "#         self.threshold = threshold\n",
        "#         self.previous_error = float('inf')\n",
        "    \n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         current_error = logs.get('loss')\n",
        "#         # print(f'\\nEpoch {epoch+1} curent Err:{current_error}, Previous Err:{self.previous_error}')\n",
        "#         if abs(current_error - self.previous_error) < self.threshold:\n",
        "#             self.model.stop_training = True\n",
        "#             print('\\n\\n********\\nThreshold Reached\\n********\\n')\n",
        "#         self.previous_error = current_error\n",
        "\n",
        "class ModelSaving(keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        self.currentEpoch = 0\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.currentEpoch = epoch\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        self.model.save(f'{pathfinal}{self.model.name}_{self.currentEpoch+1}.tf')\n",
        "        # print(\"Training has ended!, model saved\")\n",
        "\n",
        "    \n",
        "class HistorySaver(keras.callbacks.Callback):\n",
        "    def __init__(self, initial_history):\n",
        "        super(HistorySaver, self).__init__()\n",
        "        self.history = {}\n",
        "        self.currentEpoch = 0\n",
        "        \n",
        "        for key, value in [('loss', initial_history[0]), ('accuracy', initial_history[1]), ('val_loss', initial_history[2]), ('val_accuracy', initial_history[3])]:\n",
        "            self.history.setdefault(key, []).append(value)\n",
        "        \n",
        "        # logs.items() = dict_items([('loss', 1.3612865209579468), ('accuracy', 0.46034255623817444), ('val_loss', 1.1157031059265137), ('val_accuracy', 0.6484848856925964)])\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for key, value in logs.items():\n",
        "            self.history.setdefault(key, []).append(value)\n",
        "        self.currentEpoch = epoch\n",
        "        \n",
        "    def on_train_end(self, logs=None):\n",
        "        pd.DataFrame(self.history).to_csv(f'{pathfinal}{self.model.name}_{self.currentEpoch+1}.csv', index=False)\n",
        "        # print(\"Training has ended!, model history saved\")\n",
        "\n",
        "\n",
        "class HistorySaverAE(keras.callbacks.Callback):\n",
        "    def __init__(self, initial_history):\n",
        "        super(HistorySaverAE, self).__init__()\n",
        "        self.history = {}\n",
        "        self.currentEpoch = 0\n",
        "        \n",
        "        for key, value in [('loss', initial_history[0]), ('val_loss', initial_history[1])]:\n",
        "            self.history.setdefault(key, []).append(value)\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for key, value in logs.items():\n",
        "            self.history.setdefault(key, []).append(value)\n",
        "        self.currentEpoch = epoch\n",
        "\n",
        "        \n",
        "    def on_train_end(self, logs=None):\n",
        "        pd.DataFrame(self.history).to_csv(f'{pathfinal}{self.model.name}_{self.currentEpoch+1}.csv', index=False)\n",
        "        # print(\"Training has ended!, model history saved\")\n",
        "\n",
        "\n",
        "# class EndTrainingCallback(tf.keras.callbacks.Callback):\n",
        "#     def on_train_end(self, logs=None):\n",
        "#         print(\"Training has ended!\")\n",
        "\n",
        "# create the callbacks\n",
        "\n",
        "model_saver = ModelSaving()\n",
        "\n",
        "# not initialize HistorySaver() here initialize inside function \n",
        "# stop_on_threshold = StopOnThreshold(threshold=threshold_val)\n",
        "\n",
        "# This means if for 5 epochs the accuracy has no progress on \n",
        "# the validation set then it would stop and store the previous best value.\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor='loss',\n",
        "                                                  patience=1,\n",
        "                                                  min_delta=threshold_val,\n",
        "                                                  mode='min',\n",
        "                                                  restore_best_weights=True, \n",
        "                                                  verbose=0)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mcBCrQKj8Ib6"
      },
      "source": [
        "# Adam optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initializer_I = tf.keras.initializers.HeNormal(seed=random_state_global)\n",
        "# initializer_II = tf.keras.initializers.HeNormal(seed=random_state_global+1)\n",
        "# initializer_III = tf.keras.initializers.HeNormal(seed=random_state_global+2)\n",
        "# initializer_IV = tf.keras.initializers.HeNormal(seed=random_state_global+3)\n",
        "\n",
        "initializer_I = tf.keras.initializers.GlorotUniform(seed=random_state_global)\n",
        "initializer_II = tf.keras.initializers.GlorotUniform(seed=random_state_global+1)\n",
        "initializer_III = tf.keras.initializers.GlorotUniform(seed=random_state_global+2)\n",
        "initializer_IV = tf.keras.initializers.GlorotUniform(seed=random_state_global+3)\n",
        "# layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n",
        "# values = initializer(shape=(2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Autoencoder_1h_layer(Model):\n",
        "  def __init__(self, latent_dim, m_name='model'):\n",
        "    super(Autoencoder_1h_layer, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.m_name = m_name\n",
        "\n",
        "    self.encoder = keras.Sequential([\n",
        "      layers.Dense(latent_dim, activation=Hidden_layer_Activation, kernel_initializer=initializer_I),\n",
        "    ])\n",
        "\n",
        "    self.decoder = keras.Sequential([\n",
        "      layers.Dense(inputShape, activation=Output_layer_Encoder_Activation, kernel_initializer=initializer_II),\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "  # Override the name property\n",
        "  @property\n",
        "  def name(self):\n",
        "      return self.m_name\n",
        "\n",
        "class Autoencoder_3h_layer(Model):\n",
        "  def __init__(self, latent_dim, m_name='model'):\n",
        "    super(Autoencoder_3h_layer, self).__init__()\n",
        "    self.latent_dim = latent_dim   \n",
        "    self.m_name = m_name\n",
        "\n",
        "    self.encoder = keras.Sequential([\n",
        "      layers.Dense(Hidden_layer_ED_N, activation=Hidden_layer_Activation, kernel_initializer=initializer_I),\n",
        "      layers.Dense(latent_dim, activation=Hidden_layer_Activation, kernel_initializer=initializer_II),\n",
        "    ])\n",
        "\n",
        "    self.decoder = keras.Sequential([\n",
        "      layers.Dense(Hidden_layer_ED_N, activation=Hidden_layer_Activation, kernel_initializer=initializer_III),\n",
        "      layers.Dense(inputShape, activation=Output_layer_Encoder_Activation, kernel_initializer=initializer_IV),\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "  \n",
        "  # Override the name property\n",
        "  @property\n",
        "  def name(self):\n",
        "      return self.m_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-16 23:00:22.604516: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2023-04-16 23:00:22.766853: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
            "2023-04-16 23:00:24.949219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m initial_train_loss \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mevaluate(df_train\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], df_train\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     17\u001b[0m initial_valid_loss \u001b[39m=\u001b[39m autoencoder\u001b[39m.\u001b[39mevaluate(df_valid\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], df_valid\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m autoencoder\u001b[39m.\u001b[39;49mfit(df_train\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], df_train\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m],\n\u001b[1;32m     20\u001b[0m                 epochs\u001b[39m=\u001b[39;49mepoch_val,\n\u001b[1;32m     21\u001b[0m                 batch_size\u001b[39m=\u001b[39;49mbatch_size_val,\n\u001b[1;32m     22\u001b[0m                 validation_data\u001b[39m=\u001b[39;49m(df_valid\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], df_valid\u001b[39m.\u001b[39;49miloc[:,:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m     23\u001b[0m                 callbacks\u001b[39m=\u001b[39;49m[model_saver, HistorySaverAE((initial_train_loss, initial_valid_loss)), early_stopping_cb], \n\u001b[1;32m     24\u001b[0m                 verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m(i\u001b[39m<\u001b[39m\u001b[39mlen\u001b[39m(latent_dim_list)):\n\u001b[1;32m     26\u001b[0m     autoencoder_1h_list\u001b[39m.\u001b[39mappend(autoencoder)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m/opt/anaconda3/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "latent_dim_list = [32, 64, 128, 256]\n",
        "autoencoder_1h_list = []\n",
        "autoencoder_3h_list = []\n",
        "for i in range(2*len(latent_dim_list)):\n",
        "    tf.random.set_seed(random_state_global)\n",
        "\n",
        "    autoencoder = None\n",
        "    if(i<len(latent_dim_list)):\n",
        "        autoencoder = Autoencoder_1h_layer(latent_dim_list[i], m_name=f'1h_layer_ae_{latent_dim_list[i%4]}')    \n",
        "    else:\n",
        "        autoencoder = Autoencoder_3h_layer(latent_dim_list[i%4], m_name=f'3h_layer_ae_{latent_dim_list[i%4]}')\n",
        "\n",
        "    autoencoder.compile(optimizer='adam', loss=keras.losses.MeanSquaredError())\n",
        "\n",
        "    # Evaluate the model initial losses\n",
        "    initial_train_loss = autoencoder.evaluate(df_train.iloc[:,:-1], df_train.iloc[:,:-1], verbose=0)\n",
        "    initial_valid_loss = autoencoder.evaluate(df_valid.iloc[:,:-1], df_valid.iloc[:,:-1], verbose=0)\n",
        "\n",
        "    autoencoder.fit(df_train.iloc[:,:-1], df_train.iloc[:,:-1],\n",
        "                    epochs=epoch_val,\n",
        "                    batch_size=batch_size_val,\n",
        "                    validation_data=(df_valid.iloc[:,:-1], df_valid.iloc[:,:-1]),\n",
        "                    callbacks=[model_saver, HistorySaverAE((initial_train_loss, initial_valid_loss)), early_stopping_cb], \n",
        "                    verbose=0)\n",
        "    if(i<len(latent_dim_list)):\n",
        "        autoencoder_1h_list.append(autoencoder)\n",
        "    else:\n",
        "        autoencoder_3h_list.append(autoencoder)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observe  the  average  reconstruction errors  for  the  training,  validation, and  test  data.  Average reconstruction error is computed after the model is trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(latent_dim_list)):    \n",
        "    train_loss = autoencoder_1h_list[i].evaluate(df_train.iloc[:,:-1], df_train.iloc[:,:-1], verbose=0)\n",
        "    valid_loss = autoencoder_1h_list[i].evaluate(df_valid.iloc[:,:-1], df_valid.iloc[:,:-1], verbose=0)\n",
        "    test_loss = autoencoder_1h_list[i].evaluate(df_test.iloc[:,:-1], df_test.iloc[:,:-1], verbose=0)\n",
        "    print(f'1h_layer_{latent_dim_list[i]}: train_loss: {train_loss}, valid_loss: {valid_loss}, test_loss: {test_loss}')\n",
        "\n",
        "print()\n",
        "\n",
        "for i in range(len(latent_dim_list)):    \n",
        "    train_loss = autoencoder_3h_list[i].evaluate(df_train.iloc[:,:-1], df_train.iloc[:,:-1], verbose=0)\n",
        "    valid_loss = autoencoder_3h_list[i].evaluate(df_valid.iloc[:,:-1], df_valid.iloc[:,:-1], verbose=0)\n",
        "    test_loss = autoencoder_3h_list[i].evaluate(df_test.iloc[:,:-1], df_test.iloc[:,:-1], verbose=0)\n",
        "    print(f'3h_layer_{latent_dim_list[i]}: train_loss: {train_loss}, valid_loss: {valid_loss}, test_loss: {test_loss}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Take  one  image, from each  class,  from the training, validation,  and  test  set.  Give  their reconstructed images for each of the architectures ( along with original images). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plotting_data(df, titile):\n",
        "    fig, axis = plt.subplots(9, 5, figsize=(8, 20))\n",
        "    axis = axis.reshape(-1)\n",
        "    i=0\n",
        "    axis[i+2].set_title(f'({titile}) Original Images 0, 1, 2, 4, 9')\n",
        "    for num in range(5):\n",
        "        example = tf.convert_to_tensor(df.loc[df[f'{df.shape[1]-1}'] == num].iloc[:1,:-1])\n",
        "        axis[i].imshow(tf.reshape(example, shape=(28,28)))\n",
        "        axis[i].axis(False)\n",
        "        i+=1\n",
        "\n",
        "    for m in range(4):\n",
        "        axis[i+2].set_title(f'Reconstructed Images from {latent_dim_list[m]} latent dimensions and 1 Hidden layer')\n",
        "        for num in range(5):\n",
        "            example = tf.convert_to_tensor(df.loc[df.iloc[:,-1] == num].iloc[:1,:-1])\n",
        "            encoded_img = autoencoder_1h_list[m].encoder(example)\n",
        "            decoded_img = autoencoder_1h_list[m].decoder(encoded_img).numpy()\n",
        "            axis[i].imshow(decoded_img.reshape(28, 28))\n",
        "            axis[i].axis(False)\n",
        "            i+=1\n",
        "\n",
        "    for m in range(4):\n",
        "        axis[i+2].set_title(f'Reconstructed Images from {latent_dim_list[m]} latent dimensions and 3 Hidden layer')\n",
        "        for num in range(5):\n",
        "            example = tf.convert_to_tensor(df.loc[df.iloc[:,-1] == num].iloc[:1,:-1])\n",
        "            encoded_img = autoencoder_3h_list[m].encoder(example)\n",
        "            decoded_img = autoencoder_3h_list[m].decoder(encoded_img).numpy()\n",
        "            axis[i].imshow(decoded_img.reshape(28, 28))\n",
        "            axis[i].axis(False)\n",
        "            i+=1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotting_data(df_train, 'Training Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotting_data(df_valid, 'Validation Data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotting_data(df_test, 'Testing Data')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification  using  the compressed  representation  from the  1-h-l and 3-h-l  autoencoder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_X_reduced_dim_dict = {}\n",
        "df_valid_X_reduced_dim_dict = {}\n",
        "df_test_X_reduced_dim_dict = {}\n",
        "for i in range(len(latent_dim_list)):\n",
        "    df_train_X_reduced_dim_dict[f'1h_layer_{latent_dim_list[i]}'] = autoencoder_1h_list[i].encoder(tf.convert_to_tensor(df_train.iloc[:,:-1]))\n",
        "    df_train_X_reduced_dim_dict[f'3h_layer_{latent_dim_list[i]}'] = autoencoder_3h_list[i].encoder(tf.convert_to_tensor(df_train.iloc[:,:-1]))   \n",
        "    \n",
        "    df_valid_X_reduced_dim_dict[f'1h_layer_{latent_dim_list[i]}'] = autoencoder_1h_list[i].encoder(tf.convert_to_tensor(df_valid.iloc[:,:-1]))\n",
        "    df_valid_X_reduced_dim_dict[f'3h_layer_{latent_dim_list[i]}'] = autoencoder_3h_list[i].encoder(tf.convert_to_tensor(df_valid.iloc[:,:-1]))\n",
        "    \n",
        "    df_test_X_reduced_dim_dict[f'1h_layer_{latent_dim_list[i]}'] = autoencoder_1h_list[i].encoder(tf.convert_to_tensor(df_test.iloc[:,:-1]))\n",
        "    df_test_X_reduced_dim_dict[f'3h_layer_{latent_dim_list[i]}'] = autoencoder_3h_list[i].encoder(tf.convert_to_tensor(df_test.iloc[:,:-1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initializer_I = tf.keras.initializers.HeNormal(seed=random_state_global)\n",
        "# initializer_II = tf.keras.initializers.HeNormal(seed=random_state_global+1)\n",
        "# initializer_III = tf.keras.initializers.HeNormal(seed=random_state_global+2)\n",
        "# initializer_IV = tf.keras.initializers.HeNormal(seed=random_state_global+3)\n",
        "\n",
        "initializer_I = tf.keras.initializers.GlorotUniform(seed=random_state_global)\n",
        "initializer_II = tf.keras.initializers.GlorotUniform(seed=random_state_global+1)\n",
        "initializer_III = tf.keras.initializers.GlorotUniform(seed=random_state_global+2)\n",
        "initializer_IV = tf.keras.initializers.GlorotUniform(seed=random_state_global+3)\n",
        "# layer = tf.keras.layers.Dense(3, kernel_initializer=initializer)\n",
        "# values = initializer(shape=(2, 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FCNN_Classifier(Model):\n",
        "  def __init__(self, m_input_shape, m_name='model'):\n",
        "    super(FCNN_Classifier, self).__init__()\n",
        "    self.m_name = m_name\n",
        "    self.m_input_shape = m_input_shape\n",
        "\n",
        "    self.H_layer_1 = layers.Dense(Hidden_layer_I_N, activation=Hidden_layer_Activation, kernel_initializer=initializer_I, name=\"Hidden_layer_I\")\n",
        "    self.H_layer_2 = layers.Dense(Hidden_layer_II_N, activation=Hidden_layer_Activation, kernel_initializer=initializer_II,name=\"Hidden_layer_II\")\n",
        "    self.H_layer_3 = layers.Dense(Hidden_layer_III_N, activation=Hidden_layer_Activation, kernel_initializer=initializer_III,name=\"Hidden_layer_III\")\n",
        "    self.output_layer = layers.Dense(Output_layer_N, activation=Output_layer_Activation,kernel_initializer=initializer_IV, name=\"Output_layer\")\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.H_layer_1(inputs)\n",
        "    x = self.H_layer_2(x)\n",
        "    x = self.H_layer_3(x)\n",
        "    x = self.output_layer(x)\n",
        "    return x\n",
        "  \n",
        "  def build_graph(self):\n",
        "      x = layers.Input(shape=(self.m_input_shape,), name=\"Input_layer\")\n",
        "      return Model(inputs=[x], outputs=self.call(x))\n",
        "  \n",
        "  # Override the name property\n",
        "  @property\n",
        "  def name(self):\n",
        "      return self.m_name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %%script echo skipping\n",
        "\n",
        "model_dict = {}\n",
        "history_dict = {}\n",
        "\n",
        "size_dict = len(df_train_X_reduced_dim_dict)\n",
        "for i in range(size_dict):\n",
        "  # Set random seed\n",
        "  tf.random.set_seed(random_state_global)\n",
        "  \n",
        "  input_size = latent_dim_list[int(i%(size_dict/2))]\n",
        "  \n",
        "  key = None\n",
        "  if(i<(size_dict/2)):\n",
        "    key = f'1h_layer_{input_size}'\n",
        "  else:\n",
        "    key = f'3h_layer_{input_size}'\n",
        "  \n",
        "  df_tr = df_train_X_reduced_dim_dict[key]\n",
        "  df_val = df_valid_X_reduced_dim_dict[key]\n",
        "  model = FCNN_Classifier(m_input_shape=input_size, m_name=key)\n",
        "    \n",
        "\n",
        "\n",
        "  model.build(input_shape=(None, input_size)) # assuming the input shape is (batch_size, n_components_list[i])\n",
        "  \n",
        "  # Compile the model\n",
        "  model.compile(loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate=learning_rate_val, \n",
        "                                                  epsilon=epsilon_val,\n",
        "                                                  beta_1=beta_1_val,\n",
        "                                                  beta_2=beta_2_val), \n",
        "                  metrics=[\"accuracy\"])\n",
        "\n",
        "  # Evaluate the model initial losses\n",
        "  initial_train_loss, initial_train_acc = model.evaluate(df_tr, df_train.iloc[:,-1], verbose=0)\n",
        "  initial_valid_loss, initial_valid_acc = model.evaluate(df_val, df_valid.iloc[:,-1], verbose=0)\n",
        "\n",
        "  # Fit the model\n",
        "  history = model.fit(df_tr,\n",
        "                        df_train.iloc[:,-1],\n",
        "                        epochs=epoch_val,\n",
        "                        batch_size=batch_size_val,\n",
        "                        validation_data=(df_val, df_valid.iloc[:,-1]),\n",
        "                        callbacks=[model_saver, HistorySaver((initial_train_loss, initial_train_acc, initial_valid_loss, initial_valid_acc)), early_stopping_cb], verbose=0)\n",
        "\n",
        "  df_model_history = pd.DataFrame(history.history)\n",
        "  \n",
        "  model_dict[key] = model\n",
        "  history_dict[key] = df_model_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=10): \n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes), \n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "             size=text_size)\n",
        "\n",
        "def makingPredictionWithCM(model, df_test_X, df_test_Y):\n",
        "    y_true = df_test_Y\n",
        "    y_prob_a = model.predict(df_test_X, verbose=0)\n",
        "    y_pred_a = y_prob_a.argmax(axis=1)\n",
        "    make_confusion_matrix(y_true, y_pred_a, classes=list(map(lambda el: class_l_d_to_r[el], [0,1,2,3,4])))\n",
        "\n",
        "\n",
        "\n",
        "def inferences(df_model_history, model, df_test_X, df_test_Y):\n",
        "    print(f'Training Accuracy for model: {df_model_history[\"accuracy\"].to_list()[-1]*100:.2f}%')\n",
        "    print(f'Validation Accuracy for model: {df_model_history[\"val_accuracy\"].to_list()[-1]*100:.2f}%')\n",
        "    print(f'Test Accuracy for model: {model.evaluate(df_test_X, df_test_Y, verbose=0)[1]*100:.2f}%')\n",
        "\n",
        "    df_model_history.plot(title=\"Accuracy / Loss vs Epoch\", xlabel='Epoch', ylabel='Accuracy / Loss')\n",
        "    plt.show()\n",
        "\n",
        "    df_model_history['loss'].plot(title=\"Average training error vs epochs\", xlabel='Epoch', ylabel='Loss')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "size_dict = len(df_train_X_reduced_dim_dict)\n",
        "for i in range(size_dict):\n",
        "  input_size = latent_dim_list[int(i%(size_dict/2))]\n",
        "  key = None\n",
        "\n",
        "  if(i<(size_dict/2)):\n",
        "    key = f'1h_layer_{input_size}'\n",
        "  else:\n",
        "    key = f'3h_layer_{input_size}'\n",
        "\n",
        "  print('#######################################')\n",
        "  print(f'{key}_components')\n",
        "  print('#######################################')\n",
        "  makingPredictionWithCM(model_dict[key], df_test_X_reduced_dim_dict[key], df_test.iloc[:,-1])\n",
        "  inferences(history_dict[key], model_dict[key], df_test_X_reduced_dim_dict[key], df_test.iloc[:,-1])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
